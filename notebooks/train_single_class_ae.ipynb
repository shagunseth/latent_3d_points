{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a vanilla Point-Cloud AE with the basic architecture we used in our paper.\n",
    "    (it assumes latent_3d_points is in the PYTHONPATH and the structural losses have been compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/justin/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/justin/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/justin/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/justin/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/justin/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External Losses (Chamfer-EMD) were not loaded.\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from latent_3d_points.src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from latent_3d_points.src.autoencoder import Configuration as Conf\n",
    "from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from latent_3d_points.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from latent_3d_points.src.tf_utils import reset_tf_graph\n",
    "from latent_3d_points.src.general_utils import plot_3d_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the class name (e.g. \"chair\"): chair\n"
     ]
    }
   ],
   "source": [
    "top_out_dir = '../data/'          # Use to save Neural-Net check-points etc.\n",
    "top_in_dir = '../data/shape_net_core_uniform_samples_2048/' # Top-dir of where point-clouds are stored.\n",
    "\n",
    "experiment_name = 'single_class_ae'\n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "bneck_size = 128                  # Bottleneck-AE size\n",
    "ae_loss = 'chamfer'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "class_name = input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Point-Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default training parameters (some of which are listed beloq). For more details please print the configuration object.\n",
    "\n",
    "    'batch_size': 50   \n",
    "    \n",
    "    'denoising': False     (# by default AE is not denoising)\n",
    "\n",
    "    'learning_rate': 0.0005\n",
    "\n",
    "    'z_rotate': False      (# randomly rotate models of each batch)\n",
    "    \n",
    "    'loss_display_step': 1 (# display loss at end of these many epochs)\n",
    "    'saver_step': 10       (# over how many epochs to save neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = default_train_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)\n",
    "train_dir = create_dir(osp.join(top_out_dir, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the above lines, you can reload a saved model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Conf(n_input = [n_pc_points, 3],\n",
    "            loss = ae_loss,\n",
    "            training_epochs = train_params['training_epochs'],\n",
    "            batch_size = train_params['batch_size'],\n",
    "            denoising = train_params['denoising'],\n",
    "            learning_rate = train_params['learning_rate'],\n",
    "            train_dir = train_dir,\n",
    "            loss_display_step = train_params['loss_display_step'],\n",
    "            saver_step = train_params['saver_step'],\n",
    "            z_rotate = train_params['z_rotate'],\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            encoder_args = enc_args,\n",
    "            decoder_args = dec_args\n",
    "           )\n",
    "conf.experiment_name = experiment_name\n",
    "conf.held_out_step = 5   # How often to evaluate/print out loss on \n",
    "                         # held_out data (if they are provided in ae.train() ).\n",
    "conf.save(osp.join(train_dir, 'configuration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiii\n"
     ]
    }
   ],
   "source": [
    "load_pre_trained_ae = False\n",
    "restore_epoch = 500\n",
    "print ('hiii')\n",
    "if load_pre_trained_ae:\n",
    "    conf = Conf.load(train_dir + '/configuration')\n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
    "    print ('hiii' ,ae)\n",
    "    ae.restore_model(conf.train_dir, epoch=restore_epoch)\n",
    "    print (ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build AE Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n",
      "WARNING:tensorflow:From /home/justin/.local/lib/python3.5/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "encoder_conv_layer_0 conv params =  256\n",
      "bnorm params =  128\n",
      "Tensor(\"single_class_ae_2/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "output size: 131072 \n",
      "\n",
      "encoder_conv_layer_1 conv params =  8320\n",
      "bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_2 conv params =  16512\n",
      "bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_2:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_3 conv params =  33024\n",
      "bnorm params =  512\n",
      "Tensor(\"single_class_ae_2/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "output size: 524288 \n",
      "\n",
      "encoder_conv_layer_4 conv params =  32896\n",
      "bnorm params =  256\n",
      "Tensor(\"single_class_ae_2/Relu_4:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "Tensor(\"single_class_ae_2/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "decoder_fc_0 FC params =  33024\n",
      "Tensor(\"single_class_ae_2/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_1 FC params =  65792\n",
      "Tensor(\"single_class_ae_2/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_2 FC params =  1579008\n",
      "Tensor(\"single_class_ae_2/decoder_fc_2/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "output size: 6144 \n",
      "\n",
      "hiii <latent_3d_points.src.point_net_ae.PointNetAutoEncoder object at 0x7f2945af4d30>\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
    "print ('hiii' ,ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the AE (save output to train_stats.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 training time (minutes)= 0.1507 loss= 0.004165523\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0002 training time (minutes)= 0.1221 loss= 0.001719900\n",
      "Epoch: 0003 training time (minutes)= 0.1222 loss= 0.001454677\n",
      "Epoch: 0004 training time (minutes)= 0.1220 loss= 0.001364309\n",
      "Epoch: 0005 training time (minutes)= 0.1234 loss= 0.001266329\n",
      "Epoch: 0006 training time (minutes)= 0.1225 loss= 0.001217717\n",
      "Epoch: 0007 training time (minutes)= 0.1221 loss= 0.001179667\n",
      "Epoch: 0008 training time (minutes)= 0.1221 loss= 0.001133835\n",
      "Epoch: 0009 training time (minutes)= 0.1222 loss= 0.001090239\n",
      "Epoch: 0010 training time (minutes)= 0.1221 loss= 0.001054417\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0011 training time (minutes)= 0.1221 loss= 0.001016111\n",
      "Epoch: 0012 training time (minutes)= 0.1225 loss= 0.001018251\n",
      "Epoch: 0013 training time (minutes)= 0.1227 loss= 0.000974641\n",
      "Epoch: 0014 training time (minutes)= 0.1225 loss= 0.000965143\n",
      "Epoch: 0015 training time (minutes)= 0.1228 loss= 0.000961632\n",
      "Epoch: 0016 training time (minutes)= 0.1226 loss= 0.000937323\n",
      "Epoch: 0017 training time (minutes)= 0.1223 loss= 0.000923584\n",
      "Epoch: 0018 training time (minutes)= 0.1222 loss= 0.000919849\n",
      "Epoch: 0019 training time (minutes)= 0.1226 loss= 0.000894667\n",
      "Epoch: 0020 training time (minutes)= 0.1234 loss= 0.000928786\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0021 training time (minutes)= 0.1221 loss= 0.000904354\n",
      "Epoch: 0022 training time (minutes)= 0.1224 loss= 0.000895185\n",
      "Epoch: 0023 training time (minutes)= 0.1221 loss= 0.000859928\n",
      "Epoch: 0024 training time (minutes)= 0.1225 loss= 0.000855609\n",
      "Epoch: 0025 training time (minutes)= 0.1223 loss= 0.000847887\n",
      "Epoch: 0026 training time (minutes)= 0.1223 loss= 0.000843092\n",
      "Epoch: 0027 training time (minutes)= 0.1235 loss= 0.000831716\n",
      "Epoch: 0028 training time (minutes)= 0.1227 loss= 0.000843501\n",
      "Epoch: 0029 training time (minutes)= 0.1225 loss= 0.000811577\n",
      "Epoch: 0030 training time (minutes)= 0.1223 loss= 0.000812222\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-30 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0031 training time (minutes)= 0.1220 loss= 0.000822843\n",
      "Epoch: 0032 training time (minutes)= 0.1221 loss= 0.000810073\n",
      "Epoch: 0033 training time (minutes)= 0.1221 loss= 0.000793947\n",
      "Epoch: 0034 training time (minutes)= 0.1221 loss= 0.000811228\n",
      "Epoch: 0035 training time (minutes)= 0.1223 loss= 0.000781727\n",
      "Epoch: 0036 training time (minutes)= 0.1223 loss= 0.000789649\n",
      "Epoch: 0037 training time (minutes)= 0.1221 loss= 0.000766950\n",
      "Epoch: 0038 training time (minutes)= 0.1223 loss= 0.000764518\n",
      "Epoch: 0039 training time (minutes)= 0.1221 loss= 0.000771794\n",
      "Epoch: 0040 training time (minutes)= 0.1221 loss= 0.000760118\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-40 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0041 training time (minutes)= 0.1220 loss= 0.000742024\n",
      "Epoch: 0042 training time (minutes)= 0.1221 loss= 0.000762928\n",
      "Epoch: 0043 training time (minutes)= 0.1221 loss= 0.000744860\n",
      "Epoch: 0044 training time (minutes)= 0.1221 loss= 0.000744785\n",
      "Epoch: 0045 training time (minutes)= 0.1221 loss= 0.000727235\n",
      "Epoch: 0046 training time (minutes)= 0.1221 loss= 0.000741289\n",
      "Epoch: 0047 training time (minutes)= 0.1228 loss= 0.000724915\n",
      "Epoch: 0048 training time (minutes)= 0.1226 loss= 0.000736412\n",
      "Epoch: 0049 training time (minutes)= 0.1227 loss= 0.000732436\n",
      "Epoch: 0050 training time (minutes)= 0.1226 loss= 0.000718377\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0051 training time (minutes)= 0.1228 loss= 0.000720587\n",
      "Epoch: 0052 training time (minutes)= 0.1226 loss= 0.000725210\n",
      "Epoch: 0053 training time (minutes)= 0.1223 loss= 0.000703494\n",
      "Epoch: 0054 training time (minutes)= 0.1225 loss= 0.000713717\n",
      "Epoch: 0055 training time (minutes)= 0.1234 loss= 0.000720273\n",
      "Epoch: 0056 training time (minutes)= 0.1224 loss= 0.000728232\n",
      "Epoch: 0057 training time (minutes)= 0.1222 loss= 0.000702009\n",
      "Epoch: 0058 training time (minutes)= 0.1221 loss= 0.000696122\n",
      "Epoch: 0059 training time (minutes)= 0.1240 loss= 0.000690088\n",
      "Epoch: 0060 training time (minutes)= 0.1257 loss= 0.000693851\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-60 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0061 training time (minutes)= 0.1229 loss= 0.000697289\n",
      "Epoch: 0062 training time (minutes)= 0.1228 loss= 0.000673844\n",
      "Epoch: 0063 training time (minutes)= 0.1224 loss= 0.000692208\n",
      "Epoch: 0064 training time (minutes)= 0.1224 loss= 0.000674967\n",
      "Epoch: 0065 training time (minutes)= 0.1225 loss= 0.000679252\n",
      "Epoch: 0066 training time (minutes)= 0.1224 loss= 0.000675211\n",
      "Epoch: 0067 training time (minutes)= 0.1226 loss= 0.000672763\n",
      "Epoch: 0068 training time (minutes)= 0.1230 loss= 0.000685067\n",
      "Epoch: 0069 training time (minutes)= 0.1226 loss= 0.000682274\n",
      "Epoch: 0070 training time (minutes)= 0.1225 loss= 0.000663404\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-70 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0071 training time (minutes)= 0.1222 loss= 0.000667225\n",
      "Epoch: 0072 training time (minutes)= 0.1222 loss= 0.000670058\n",
      "Epoch: 0073 training time (minutes)= 0.1225 loss= 0.000674091\n",
      "Epoch: 0074 training time (minutes)= 0.1223 loss= 0.000662144\n",
      "Epoch: 0075 training time (minutes)= 0.1226 loss= 0.000668299\n",
      "Epoch: 0076 training time (minutes)= 0.1228 loss= 0.000640569\n",
      "Epoch: 0077 training time (minutes)= 0.1226 loss= 0.000662836\n",
      "Epoch: 0078 training time (minutes)= 0.1227 loss= 0.000650360\n",
      "Epoch: 0079 training time (minutes)= 0.1227 loss= 0.000658202\n",
      "Epoch: 0080 training time (minutes)= 0.1228 loss= 0.000632596\n",
      "INFO:tensorflow:../data/single_class_ae/models.ckpt-80 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0081 training time (minutes)= 0.1224 loss= 0.000659569\n",
      "Epoch: 0082 training time (minutes)= 0.1224 loss= 0.000642613\n",
      "Epoch: 0083 training time (minutes)= 0.1225 loss= 0.000647573\n",
      "Epoch: 0084 training time (minutes)= 0.1228 loss= 0.000636726\n",
      "Epoch: 0085 training time (minutes)= 0.1228 loss= 0.000632800\n",
      "Epoch: 0086 training time (minutes)= 0.1225 loss= 0.000626727\n"
     ]
    }
   ],
   "source": [
    "buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
    "fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch of reconstuctions and their latent-codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use any plotting mechanism such as matplotlib to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feed_pc, feed_model_names, _ = all_pc_data.next_batch(10)\n",
    "reconstructions = ae.reconstruct(feed_pc)[0]\n",
    "latent_codes = ae.transform(feed_pc)\n",
    "\n",
    "\n",
    "for x in range(0, 2048):\n",
    "    print (reconstructions[:][0, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print ('Shape of DATA =', reconstructions[i][:, 0])\n",
    "print ('Shape of DATA =', reconstructions[i][:, 1])\n",
    "print ('Shape of DATA =', reconstructions[i][:, 2])\n",
    "i = 0\n",
    "plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "                    reconstructions[i][:, 1], \n",
    "                    reconstructions[i][:, 2], in_u_sphere=True);\n",
    "\n",
    "print (plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "                    reconstructions[i][:, 1], \n",
    "                    reconstructions[i][:, 2], in_u_sphere=True))\n",
    "\n",
    "i = 2\n",
    "plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "                    reconstructions[i][:, 1], \n",
    "                    reconstructions[i][:, 2], in_u_sphere=True);\n",
    "\n",
    "print ('Shape of DATA =', reconstructions[i][:, 0])\n",
    "print ('Shape of DATA =', reconstructions[i][:, 1])\n",
    "print ('Shape of DATA =', reconstructions[i][:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
